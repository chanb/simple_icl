{
    "logging_config": {
        "save_path": "<TO_FILL>",
        "experiment_name": "<TO_FILL>",
        "log_interval": 50,
        "checkpoint_interval": 10000
    },
    "model_config": {
        "architecture": "InContextSupervisedTransformer",
        "model_kwargs": {
            "output_dim": 2,
            "num_contexts": 4,
            "num_blocks": 2,
            "num_heads": 1,
            "embed_dim": 64,
            "widening_factor": 4,
            "query_pred_only": true
        }
    },
    "optimizer_config": {
        "optimizer": "adam",
        "lr": {
            "scheduler": "constant_schedule",
            "scheduler_kwargs": {
                "value": 3e-4
            }
        },
        "opt_kwargs": {},
        "max_grad_norm": false,
        "mask_names": ["input_tokenizer"]
    },
    "dataset_name": "binary_synthetic",
    "dataset_kwargs": {
        "dataset_size": 64,
        "num_high_freq_classes": 5,
        "num_low_freq_classes": 100000,
        "p_balance": 0.5,
        "p_high": 0.9,
        "num_dims": 64,
        "train": true,
        "num_contexts": 4,
        "input_noise_std": 0.01,
        "label_noise": 0.1,
        "example_space": "standard_basis",
        "conditioning": "none",
        "flip_label": true,
        "num_relevant_contexts": 2
    },
    "shuffle_buffer_size": 100,
    "num_workers": 2,
    "batch_size": 32,
    "num_epochs": 500000,
    "num_updates_per_epoch": 1,
    "seeds": {
        "learner_seed": 46,
        "data_seed": 46
    }
}