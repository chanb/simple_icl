{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "sys.path.insert(0, \"../src\")\n",
    "\n",
    "from experiments.utils import *\n",
    "\n",
    "from src.constants import *\n",
    "from src.dataset import get_data_loader\n",
    "from src.models import SimpleICLModel, SimpleICLModelLearnedIWPredictor\n",
    "from src.utils import parse_dict, load_config, iterate_models, set_seed\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import os\n",
    "\n",
    "# Penzai\n",
    "from penzai import pz\n",
    "\n",
    "import IPython\n",
    "\n",
    "pz.ts.register_as_default()\n",
    "\n",
    "# Optional automatic array visualization extras:\n",
    "pz.ts.register_autovisualize_magic()\n",
    "pz.enable_interactive_context()\n",
    "pz.ts.active_autovisualizer.set_interactive(pz.ts.ArrayAutovisualizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"/Users/chanb/research/ualberta/simple_icl/experiments/results\"\n",
    "experiment_name = \"high_prob_0.99\"\n",
    "variant = \"transformer-09-02-24_13_39_27-bf1eeb21-928a-4829-b008-f82e5369e4d0\"\n",
    "\n",
    "learner_path = os.path.join(log_dir, experiment_name, variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict, config = load_config(learner_path)\n",
    "config_dict[\"batch_size\"] = 1\n",
    "config = parse_dict(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader, train_dataset = get_data_loader(\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iter = iterate_models(\n",
    "    learner_path\n",
    ")\n",
    "\n",
    "params_init, model, checkpoint_step_init = next(model_iter)\n",
    "\n",
    "for _ in range(40):\n",
    "    params_next, _, checkpoint_step_next = next(model_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_data_loader:\n",
    "    if np.argmax(batch[\"target\"][0, -1], axis=-1) == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dict()\n",
    "for params, checkpoint_step in zip(\n",
    "    [params_init, params_next],\n",
    "    [checkpoint_step_init, checkpoint_step_next]\n",
    "):\n",
    "    out, aux = model.get_attention(\n",
    "        params[CONST_MODEL],\n",
    "        batch,\n",
    "        eval=True,\n",
    "    )\n",
    "\n",
    "    result[checkpoint_step] = dict()\n",
    "    for block in aux[\"gpt\"][\"intermediates\"]:\n",
    "        if not block.startswith(\"GPTBlock_\"):\n",
    "            continue\n",
    "\n",
    "        # axis=1 -> query\n",
    "        # axis=2 -> key\n",
    "        self_attention_map = aux[\"gpt\"][\"intermediates\"][block][\"SelfAttentionModule_0\"][\"attention\"][0][0]\n",
    "        self_attention_map = self_attention_map.at[self_attention_map <= -1e10].set(jnp.nan)\n",
    "\n",
    "        attention_score = jnp.sum(aux[\"gpt\"][\"intermediates\"][block][\"attention\"][0][0], axis=-1)\n",
    "        input_vector = jnp.sum(aux[\"gpt\"][\"intermediates\"][block][\"input\"][0][0], axis=-1)\n",
    "        block_output = jnp.sum(aux[\"gpt\"][\"intermediates\"][block][\"block_out\"][0][0], axis=-1)\n",
    "\n",
    "        result[checkpoint_step][block] = dict(\n",
    "            self_attention_map=self_attention_map,\n",
    "            attention_score=jnp.vstack(\n",
    "                (\n",
    "                    np.argmax(batch[\"target\"][0], axis=-1),\n",
    "                    attention_score[::2],\n",
    "                    jnp.concatenate((attention_score[1::2], jnp.array([jnp.nan])), axis=-1),\n",
    "                )\n",
    "            ),\n",
    "            input_vector=jnp.vstack(\n",
    "                (\n",
    "                    np.argmax(batch[\"target\"][0], axis=-1),\n",
    "                    input_vector[::2],\n",
    "                    jnp.concatenate((input_vector[1::2], jnp.array([jnp.nan])), axis=-1),\n",
    "                )\n",
    "            ),\n",
    "            block_output=jnp.vstack(\n",
    "                (\n",
    "                    np.argmax(batch[\"target\"][0], axis=-1),\n",
    "                    block_output[::2],\n",
    "                    jnp.concatenate((block_output[1::2], jnp.array([jnp.nan])), axis=-1),\n",
    "                )\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz.ts.display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"outputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
