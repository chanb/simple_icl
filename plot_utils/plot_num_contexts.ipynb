{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "611aa6db-9102-41d8-a575-6da09450a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import timeit\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from utils import set_size, pgf_with_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9bd8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-v0_8-colorblind\")\n",
    "# But with fonts from the document body\n",
    "plt.rcParams.update(pgf_with_latex)\n",
    "\n",
    "# Using the set_size function as defined earlier\n",
    "doc_width_pt = 452.9679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1b7a68a-60d0-4758-b3f9-b5ef665b2722",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_eval_name = {\n",
    "    \"pretraining\": \"\",\n",
    "    \"pretrain-sample_high_prob_class_only-start_pos_0\": \"Condition on High Frequency\",\n",
    "    \"pretrain-sample_low_prob_class_only-start_pos_0\": \"Condition on Low Frequency\",\n",
    "    \"pretrain-sample_high_prob_class_only-start_pos_0-flip_label\": \"Condition on High Frequency\",\n",
    "    \"pretrain-sample_low_prob_class_only-start_pos_0-flip_label\": \"Condition on Low Frequency\",\n",
    "    \n",
    "    \"pretrain-sample_high_prob_class_only-start_pos_1\": \"Condition on High Frequency\",\n",
    "    \"pretrain-sample_low_prob_class_only-start_pos_1\": \"Condition on Low Frequency\",\n",
    "    \"pretrain-sample_high_prob_class_only-start_pos_1-flip_label\": \"Condition on High Frequency\",\n",
    "    \"pretrain-sample_low_prob_class_only-start_pos_1-flip_label\": \"Condition on Low Frequency\",\n",
    "    \n",
    "    \"pretrain-sample_high_prob_class_only-start_pos_7\": \"Condition on High Frequency\",\n",
    "    \"pretrain-sample_low_prob_class_only-start_pos_7\": \"Condition on Low Frequency\",\n",
    "    \"pretrain-sample_high_prob_class_only-start_pos_7-flip_label\": \"Condition on High Frequency\",\n",
    "    \"pretrain-sample_low_prob_class_only-start_pos_7-flip_label\": \"Condition on Low Frequency\",\n",
    "\n",
    "    \"eval-relevant_context-none\": \"Relevant Context\",\n",
    "    \"eval-irrelevant_context-none\": \"Irrelevant Context\",\n",
    "}\n",
    "\n",
    "stats_keys = [\n",
    "    \"accuracy\",\n",
    "    \"p_iwl\",\n",
    "    \"context contains query class\",\n",
    "    \"loss\",\n",
    "    \"ic_pred\",\n",
    "    \"iw_pred\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc71aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"/Users/chanb/research/ualberta/icl/simple_icl\"\n",
    "results_dir = \"/Users/chanb/research/ualberta/icl/cc_results/paper_experiments/evaluation_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e5fe6a4-d543-4e4e-9857-94bb492adc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_name = \"synthetic-transformer-num_contexts\"\n",
    "\n",
    "checkpoint_steps = 500\n",
    "\n",
    "stats_file = os.path.join(repo_path, \"plot_utils/plots/agg_stats\", \"{}.feather\".format(variant_name))\n",
    "stats = pd.read_feather(stats_file)\n",
    "\n",
    "os.makedirs(\n",
    "    os.path.join(repo_path, \"plot_utils/plots/acc-plots\", variant_name),\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "results_dir = os.path.join(results_dir, variant_name)\n",
    "eval_namess = [\n",
    "    [\n",
    "        \"pretraining\"\n",
    "    ],\n",
    "    [\n",
    "        \"eval-relevant_context-none\",\n",
    "        \"eval-irrelevant_context-none\",\n",
    "    ],\n",
    "    [\n",
    "        \"pretrain-sample_high_prob_class_only-start_pos_0\",\n",
    "        \"pretrain-sample_low_prob_class_only-start_pos_0\",\n",
    "    ],\n",
    "    [\n",
    "        \"pretrain-sample_high_prob_class_only-start_pos_0-flip_label\",\n",
    "        \"pretrain-sample_low_prob_class_only-start_pos_0-flip_label\",\n",
    "    ],\n",
    "    [\n",
    "        \"pretrain-sample_high_prob_class_only-start_pos_1\",\n",
    "        \"pretrain-sample_low_prob_class_only-start_pos_1\",\n",
    "    ],\n",
    "    [\n",
    "        \"pretrain-sample_high_prob_class_only-start_pos_1-flip_label\",\n",
    "        \"pretrain-sample_low_prob_class_only-start_pos_1-flip_label\",\n",
    "    ],\n",
    "    [\n",
    "        \"pretrain-sample_high_prob_class_only-start_pos_7\",\n",
    "        \"pretrain-sample_low_prob_class_only-start_pos_7\",\n",
    "    ],\n",
    "    [\n",
    "        \"pretrain-sample_high_prob_class_only-start_pos_7-flip_label\",\n",
    "        \"pretrain-sample_low_prob_class_only-start_pos_7-flip_label\",\n",
    "    ],\n",
    "]\n",
    "plot_names = [\n",
    "    \"pretraining\",\n",
    "    \"context-default\",\n",
    "    \"iwl\",\n",
    "    \"iwl-flip_label\",\n",
    "    \"icl-last_context\",\n",
    "    \"icl-last_context-flip_label\",\n",
    "    \"icl-except_first_context\",\n",
    "    \"icl-except_first_context-flip_label\",\n",
    "]\n",
    "plot_titles = [\n",
    "    \"Pretraining\",\n",
    "    \"Context Default\"\n",
    "    \"In-weight Evaluation\",\n",
    "    \"In-weight Evaluation with Flipped Label\",\n",
    "    \"In-context Evaluation with Last Context\",\n",
    "    \"In-context Evaluation with Last Context + Flipped Label\",\n",
    "    \"In-context Evaluation with Contexts but First\",\n",
    "    \"In-context Evaluation with Contexts but First + Flipped Label\",\n",
    "]\n",
    "\n",
    "map_stats_key = {\n",
    "    \"p_iwl\": \"$\\\\alpha(x)$\",\n",
    "    \"accuracy\": \"Accuracy\",\n",
    "    \"context contains query class\": \"Context Contains Query Class\",\n",
    "    \"loss\": \"Loss\",\n",
    "    \"ic_pred\": \"In-context Accuracy\",\n",
    "    \"iw_pred\": \"In-weight Accuracy\"\n",
    "}\n",
    "\n",
    "map_variant = {\n",
    "    \"ground_truth_prob\": \"$P(g(x) = c)$\",\n",
    "    \"high_prob\": \"$P(high\\_freq.)$\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f9f88e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = stats[\"variant\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040a7140",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d095e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985cbd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = sorted([int(dataset_size) for dataset_size in stats[\"dataset_size\"].unique()])\n",
    "num_contextss = sorted([int(num_contexts) for num_contexts in stats[\"num_contexts\"].unique()])\n",
    "num_contextss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dfab1b",
   "metadata": {},
   "source": [
    "# Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bb961e",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "389341b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idxes = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea60e9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_label = {\n",
    "    0.0: \"IW Predictor\",\n",
    "    1.0: \"IC Predictor\",\n",
    "    0.9: \"Transformer\",\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(8, 3))\n",
    "for ax_i, p_relevant_context in enumerate([0.0, 1.0, 0.9]):\n",
    "    ax = axes[ax_i]\n",
    "    for variant_i, num_contexts in enumerate(num_contextss):\n",
    "        losses_mean = []\n",
    "        losses_std = []\n",
    "\n",
    "        for dataset_size in dataset_sizes:\n",
    "            data = (np.array(stats[\n",
    "                (stats[\"p_relevant_context\"] == f\"{p_relevant_context}\")\n",
    "                & (stats[\"num_contexts\"] == f\"{num_contexts}\")\n",
    "                & (stats[\"stats_key\"] == \"loss\")\n",
    "                & (stats[\"eval_name\"] == \"pretraining\")\n",
    "                & (stats[\"dataset_size\"] == f\"{dataset_size}\")\n",
    "            ][\"stats\"].to_list()))\n",
    "            best_idx = data.shape[1] - np.argmin(data[:, ::-1], axis=-1) - 1\n",
    "\n",
    "            best_idxes[(\n",
    "                p_relevant_context, num_contexts, dataset_size\n",
    "            )] = best_idx\n",
    "\n",
    "            sample = data[np.arange(5), best_idx]\n",
    "            curr_mean = np.mean(sample)\n",
    "            curr_std = np.std(sample)\n",
    "\n",
    "            losses_mean.append(curr_mean)\n",
    "            losses_std.append(curr_std)\n",
    "\n",
    "        losses_mean = np.array(losses_mean)\n",
    "        losses_std = np.array(losses_std) / np.sqrt(5)\n",
    "\n",
    "        ax.plot(np.log2(np.array(dataset_sizes)), losses_mean, label=num_contexts if ax_i == 0 else \"\")\n",
    "        ax.fill_between(np.log2(np.array(dataset_sizes)), losses_mean - losses_std, losses_mean + losses_std, alpha=0.3)\n",
    "\n",
    "    ax.set_title(map_label[p_relevant_context])\n",
    "    # ax.set_ylim(0.0, 0.009)\n",
    "\n",
    "fig.supylabel(\"Cross-entropy Loss\")\n",
    "fig.supxlabel(\"Dataset Size (in $\\\\log_2$)\")\n",
    "fig.legend(\n",
    "    bbox_to_anchor=(0.0, 1.0, 1.0, 0.0),\n",
    "    loc=\"lower center\",\n",
    "    ncols=5,\n",
    "    borderaxespad=0.0,\n",
    "    frameon=True,\n",
    "    fontsize=\"8\", \n",
    ")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec7c64d",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983ec8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_label = {\n",
    "    0.0: \"IW Predictor\",\n",
    "    1.0: \"IC Predictor\",\n",
    "    0.9: \"Transformer\",\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(8, 3))\n",
    "for ax_i, p_relevant_context in enumerate([0.0, 1.0, 0.9]):\n",
    "    ax = axes[ax_i]\n",
    "    for variant_i, num_contexts in enumerate(num_contextss):\n",
    "        losses_mean = []\n",
    "        losses_std = []\n",
    "\n",
    "        for dataset_size in dataset_sizes:\n",
    "            data = 1 - (np.array(stats[\n",
    "                (stats[\"p_relevant_context\"] == f\"{p_relevant_context}\")\n",
    "                & (stats[\"num_contexts\"] == f\"{num_contexts}\")\n",
    "                & (stats[\"stats_key\"] == \"accuracy\")\n",
    "                & (stats[\"eval_name\"] == \"pretraining\")\n",
    "                & (stats[\"dataset_size\"] == f\"{dataset_size}\")\n",
    "            ][\"stats\"].to_list()))\n",
    "            best_idx = best_idxes[(\n",
    "                p_relevant_context, num_contexts, dataset_size\n",
    "            )]\n",
    "            sample = data[np.arange(5), best_idx]\n",
    "            curr_mean = np.mean(sample)\n",
    "            curr_std = np.std(sample)\n",
    "            \n",
    "            losses_mean.append(curr_mean)\n",
    "            losses_std.append(curr_std)\n",
    "\n",
    "        losses_mean = np.array(losses_mean)\n",
    "        losses_std = np.array(losses_std) / np.sqrt(5)\n",
    "\n",
    "        ax.plot(np.log2(np.array(dataset_sizes)), losses_mean, label=num_contexts if ax_i == 0 else \"\")\n",
    "        ax.fill_between(np.log2(np.array(dataset_sizes)), losses_mean - losses_std, losses_mean + losses_std, alpha=0.3)\n",
    "\n",
    "    ax.set_title(map_label[p_relevant_context])\n",
    "    ax.set_ylim(0.0, 1.1)\n",
    "    ax.axhline(9/10, label=\"Chance\" if ax_i == 0 else \"\", c=\"red\", linestyle=\"--\")\n",
    "\n",
    "fig.supylabel(\"0-1 Error\")\n",
    "fig.supxlabel(\"Dataset Size (in $\\\\log_2$)\")\n",
    "fig.legend(\n",
    "    bbox_to_anchor=(0.0, 1.0, 1.0, 0.0),\n",
    "    loc=\"lower center\",\n",
    "    ncols=6,\n",
    "    borderaxespad=0.0,\n",
    "    frameon=True,\n",
    "    fontsize=\"8\", \n",
    ")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789213c5",
   "metadata": {},
   "source": [
    "## General Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6989a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_label = {\n",
    "    0.0: \"IW Predictor\",\n",
    "    1.0: \"IC Predictor\",\n",
    "    0.9: \"Transformer\",\n",
    "}\n",
    "map_eval = {\n",
    "    \"eval-relevant_context-high_prob\": \"Rel. Context, High-freq.\",\n",
    "    \"eval-relevant_context-low_prob\": \"Rel. Context, Low-freq.\",\n",
    "    \"eval-irrelevant_context-high_prob\": \"Irrel. Context, High-freq.\",\n",
    "    \"eval-irrelevant_context-low_prob\": \"Irrel. Context, Low-freq.\",\n",
    "    \"eval-relevant_context-high_prob-flip_label\": \"Rel. Context, High-freq.\",\n",
    "    \"eval-relevant_context-low_prob-flip_label\": \"Rel. Context, Low-freq.\",\n",
    "    \"eval-irrelevant_context-high_prob-flip_label\": \"Irrel. Context, High-freq.\",\n",
    "    \"eval-irrelevant_context-low_prob-flip_label\": \"Irrel. Context, Low-freq.\",\n",
    "}\n",
    "\n",
    "eval_namess = [\n",
    "    [\n",
    "        \"eval-relevant_context-high_prob\",\n",
    "        \"eval-relevant_context-low_prob\",\n",
    "        \"eval-irrelevant_context-high_prob\",\n",
    "        \"eval-irrelevant_context-low_prob\",\n",
    "    ],\n",
    "    [\n",
    "        \"eval-relevant_context-high_prob-flip_label\",\n",
    "        \"eval-relevant_context-low_prob-flip_label\",\n",
    "        \"eval-irrelevant_context-high_prob-flip_label\",\n",
    "        \"eval-irrelevant_context-low_prob-flip_label\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "for num_contexts in num_contextss:\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(10, 5))\n",
    "    for row_i, eval_names in enumerate(eval_namess):\n",
    "        for eval_i, eval_name in enumerate(eval_names):\n",
    "            ax = axes[row_i, eval_i]\n",
    "            # ax = axes[eval_i]\n",
    "            for p_relevant_context in [0.0, 0.9, 1.0]:\n",
    "                losses_mean = []\n",
    "                losses_std = []\n",
    "\n",
    "                for dataset_size in dataset_sizes:\n",
    "                    data = (np.array(stats[\n",
    "                        (stats[\"p_relevant_context\"] == f\"{p_relevant_context}\")\n",
    "                        & (stats[\"num_contexts\"] == f\"{num_contexts}\")\n",
    "                        & (stats[\"stats_key\"] == \"loss\")\n",
    "                        & (stats[\"eval_name\"] == eval_name)\n",
    "                        & (stats[\"dataset_size\"] == f\"{dataset_size}\")\n",
    "                    ][\"stats\"].to_list()))\n",
    "                    best_idx = best_idxes[(\n",
    "                        p_relevant_context, num_contexts, dataset_size\n",
    "                    )]\n",
    "                    sample = data[np.arange(5), best_idx]\n",
    "                    curr_mean = np.mean(sample)\n",
    "                    curr_std = np.std(sample)\n",
    "                    \n",
    "                    losses_mean.append(curr_mean)\n",
    "                    losses_std.append(curr_std)\n",
    "\n",
    "                losses_mean = np.array(losses_mean)\n",
    "                losses_std = np.array(losses_std) / np.sqrt(5)\n",
    "\n",
    "                ax.plot(np.log2(np.array(dataset_sizes)), losses_mean, label=map_label[p_relevant_context] if eval_i == 0 and row_i == 0 else \"\")\n",
    "                ax.fill_between(np.log2(np.array(dataset_sizes)), losses_mean - losses_std, losses_mean + losses_std, alpha=0.3)\n",
    "\n",
    "            ax.set_title(map_eval[eval_name])\n",
    "            # ax.set_ylim(-1.0, 1.5)\n",
    "            if eval_i == 0:\n",
    "                ax.set_ylabel(\"In-base Dist.\" if row_i == 0 else \"Out-of-base Dist.\")\n",
    "\n",
    "    fig.suptitle(\"Context Length: {}\".format(num_contexts))\n",
    "    fig.supylabel(\"Cross-entropy Loss\")\n",
    "    fig.supxlabel(\"Dataset Size (in $\\\\log_2$)\")\n",
    "    fig.legend(\n",
    "        bbox_to_anchor=(0.0, 1.0, 1.0, 0.0),\n",
    "        loc=\"lower center\",\n",
    "        ncols=4,\n",
    "        borderaxespad=0.0,\n",
    "        frameon=True,\n",
    "        fontsize=\"8\", \n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd7b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_label = {\n",
    "    0.0: \"IW Predictor\",\n",
    "    1.0: \"IC Predictor\",\n",
    "    0.9: \"Transformer\",\n",
    "}\n",
    "map_eval = {\n",
    "    \"eval-relevant_context-high_prob\": \"Rel. Context, High-freq.\",\n",
    "    \"eval-relevant_context-low_prob\": \"Rel. Context, Low-freq.\",\n",
    "    \"eval-irrelevant_context-high_prob\": \"Irrel. Context, High-freq.\",\n",
    "    \"eval-irrelevant_context-low_prob\": \"Irrel. Context, Low-freq.\",\n",
    "    \"eval-relevant_context-high_prob-flip_label\": \"Rel. Context, High-freq.\",\n",
    "    \"eval-relevant_context-low_prob-flip_label\": \"Rel. Context, Low-freq.\",\n",
    "    \"eval-irrelevant_context-high_prob-flip_label\": \"Irrel. Context, High-freq.\",\n",
    "    \"eval-irrelevant_context-low_prob-flip_label\": \"Irrel. Context, Low-freq.\",\n",
    "}\n",
    "\n",
    "eval_namess = [\n",
    "    [\n",
    "        \"eval-relevant_context-high_prob\",\n",
    "        \"eval-relevant_context-low_prob\",\n",
    "        \"eval-irrelevant_context-high_prob\",\n",
    "        \"eval-irrelevant_context-low_prob\",\n",
    "    ],\n",
    "    [\n",
    "        \"eval-relevant_context-high_prob-flip_label\",\n",
    "        \"eval-relevant_context-low_prob-flip_label\",\n",
    "        \"eval-irrelevant_context-high_prob-flip_label\",\n",
    "        \"eval-irrelevant_context-low_prob-flip_label\",\n",
    "    ],\n",
    "]\n",
    "for num_contexts in num_contextss:\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(10, 5))\n",
    "    for row_i, eval_names in enumerate(eval_namess):\n",
    "        for eval_i, eval_name in enumerate(eval_names):\n",
    "            ax = axes[row_i, eval_i]\n",
    "            # ax = axes[eval_i]\n",
    "            for p_relevant_context in [0.0, 0.9, 1.0]:\n",
    "                losses_mean = []\n",
    "                losses_std = []\n",
    "\n",
    "                for dataset_size in dataset_sizes:\n",
    "                    data = 1 - (np.array(stats[\n",
    "                        (stats[\"p_relevant_context\"] == f\"{p_relevant_context}\")\n",
    "                        & (stats[\"num_contexts\"] == f\"{num_contexts}\")\n",
    "                        & (stats[\"stats_key\"] == \"accuracy\")\n",
    "                        & (stats[\"eval_name\"] == eval_name)\n",
    "                        & (stats[\"dataset_size\"] == f\"{dataset_size}\")\n",
    "                    ][\"stats\"].to_list()))\n",
    "                    best_idx = best_idxes[(\n",
    "                        p_relevant_context, num_contexts, dataset_size\n",
    "                    )]\n",
    "                    sample = data[np.arange(5), best_idx]\n",
    "                    curr_mean = np.mean(sample)\n",
    "                    curr_std = np.std(sample)\n",
    "                    \n",
    "                    losses_mean.append(curr_mean)\n",
    "                    losses_std.append(curr_std)\n",
    "\n",
    "                losses_mean = np.array(losses_mean)\n",
    "                losses_std = np.array(losses_std) / np.sqrt(5)\n",
    "\n",
    "                ax.plot(np.log2(np.array(dataset_sizes)), losses_mean, label=map_label[p_relevant_context] if eval_i == 0 and row_i == 0 else \"\")\n",
    "                ax.fill_between(np.log2(np.array(dataset_sizes)), losses_mean - losses_std, losses_mean + losses_std, alpha=0.3)\n",
    "\n",
    "            ax.set_title(map_eval[eval_name])\n",
    "            ax.axhline(9/10, label=\"Chance\" if eval_i == 0 and row_i == 0 else \"\", c=\"red\", linestyle=\"--\")\n",
    "            ax.set_ylim(-0.1, 1.1)\n",
    "\n",
    "            if eval_i == 0:\n",
    "                ax.set_ylabel(\"In-base Dist.\" if row_i == 0 else \"Out-of-base Dist.\")\n",
    "\n",
    "    fig.suptitle(\"Context Length: {}\".format(num_contexts))\n",
    "    fig.supylabel(\"0-1 Error\")\n",
    "    fig.supxlabel(\"Dataset Size (in $\\\\log_2$)\")\n",
    "    fig.legend(\n",
    "        bbox_to_anchor=(0.0, 1.0, 1.0, 0.0),\n",
    "        loc=\"lower center\",\n",
    "        ncols=4,\n",
    "        borderaxespad=0.0,\n",
    "        frameon=True,\n",
    "        fontsize=\"8\", \n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaceadba",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[\"eval_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff20de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_label = {\n",
    "    0.0: \"IW Predictor\",\n",
    "    1.0: \"IC Predictor\",\n",
    "    0.9: \"Transformer\",\n",
    "}\n",
    "map_eval = {\n",
    "    \"eval-relevant_context-high_prob\": \"Rel. Context, High-freq.\",\n",
    "    \"eval-relevant_context-low_prob\": \"Rel. Context, Low-freq.\",\n",
    "    \"eval-irrelevant_context-high_prob\": \"Irrel. Context, High-freq.\",\n",
    "    \"eval-irrelevant_context-low_prob\": \"Irrel. Context, Low-freq.\",\n",
    "    \"eval-relevant_context-high_prob-flip_label\": \"Rel. Context, High-freq.\",\n",
    "    \"eval-relevant_context-low_prob-flip_label\": \"Rel. Context, Low-freq.\",\n",
    "    \"eval-irrelevant_context-high_prob-flip_label\": \"Irrel. Context, High-freq.\",\n",
    "    \"eval-irrelevant_context-low_prob-flip_label\": \"Irrel. Context, Low-freq.\",\n",
    "    \"eval-relevant_context-none\": \"Rel. Context, IBD\",\n",
    "    \"eval-relevant_context-none-flip_label\": \"Rel. Context, OOBD\",\n",
    "    \"eval-irrelevant_context-none\": \"Irrel. Context, High-freq., IBD\",\n",
    "    \"eval-irrelevant_context-none-flip_label\": \"Irrel. Context, OOBD\",\n",
    "}\n",
    "\n",
    "eval_names = [\n",
    "    \"eval-relevant_context-none\",\n",
    "    \"eval-irrelevant_context-none\",\n",
    "    \"eval-relevant_context-none-flip_label\",\n",
    "    \"eval-irrelevant_context-none-flip_label\",\n",
    "]\n",
    "for num_contexts in num_contextss:\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(10, 3))\n",
    "    for eval_i, eval_name in enumerate(eval_names):\n",
    "        ax = axes[eval_i]\n",
    "        for p_relevant_context in [0.0, 0.9, 1.0]:\n",
    "            losses_mean = []\n",
    "            losses_std = []\n",
    "\n",
    "            for dataset_size in dataset_sizes:\n",
    "                data = 1 - (np.array(stats[\n",
    "                    (stats[\"p_relevant_context\"] == f\"{p_relevant_context}\")\n",
    "                    & (stats[\"num_contexts\"] == f\"{num_contexts}\")\n",
    "                    & (stats[\"stats_key\"] == \"accuracy\")\n",
    "                    & (stats[\"eval_name\"] == eval_name)\n",
    "                    & (stats[\"dataset_size\"] == f\"{dataset_size}\")\n",
    "                ][\"stats\"].to_list()))\n",
    "                best_idx = best_idxes[(\n",
    "                    p_relevant_context, num_contexts, dataset_size\n",
    "                )]\n",
    "                sample = data[np.arange(5), best_idx]\n",
    "                curr_mean = np.mean(sample)\n",
    "                curr_std = np.std(sample)\n",
    "                \n",
    "                losses_mean.append(curr_mean)\n",
    "                losses_std.append(curr_std)\n",
    "\n",
    "            losses_mean = np.array(losses_mean)\n",
    "            losses_std = np.array(losses_std) / np.sqrt(5)\n",
    "\n",
    "            ax.plot(np.log2(np.array(dataset_sizes)), losses_mean, label=map_label[p_relevant_context] if eval_i == 0 else \"\")\n",
    "            ax.fill_between(np.log2(np.array(dataset_sizes)), losses_mean - losses_std, losses_mean + losses_std, alpha=0.3)\n",
    "\n",
    "        ax.set_title(map_eval[eval_name])\n",
    "        ax.axhline(9/10, label=\"Chance\" if eval_i == 0 else \"\", c=\"red\", linestyle=\"--\")\n",
    "        ax.set_ylim(-0.1, 1.1)\n",
    "\n",
    "    fig.suptitle(\"Context Length: {}\".format(num_contexts))\n",
    "    fig.supylabel(\"0-1 Error\")\n",
    "    fig.supxlabel(\"Dataset Size (in $\\\\log_2$)\")\n",
    "    fig.legend(\n",
    "        bbox_to_anchor=(0.0, 1.0, 1.0, 0.0),\n",
    "        loc=\"lower center\",\n",
    "        ncols=4,\n",
    "        borderaxespad=0.0,\n",
    "        frameon=True,\n",
    "        fontsize=\"8\", \n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd4c8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as plticker\n",
    "map_label = {\n",
    "    0.0: \"IW Predictor\",\n",
    "    1.0: \"IC Predictor\",\n",
    "    0.9: \"Transformer\",\n",
    "}\n",
    "map_eval = {\n",
    "    \"eval-relevant_context-high_prob\": \"Rel. Context, High-freq.\",\n",
    "    \"eval-relevant_context-low_prob\": \"Rel. Context, Low-freq.\",\n",
    "    \"eval-irrelevant_context-high_prob\": \"Irrel. Context, High-freq.\",\n",
    "    \"eval-irrelevant_context-low_prob\": \"Irrel. Context, Low-freq.\",\n",
    "    \"eval-relevant_context-high_prob-flip_label\": \"Rel. Context, High-freq.\",\n",
    "    \"eval-relevant_context-low_prob-flip_label\": \"Rel. Context, Low-freq.\",\n",
    "    \"eval-irrelevant_context-high_prob-flip_label\": \"Irrel. Context, High-freq.\",\n",
    "    \"eval-irrelevant_context-low_prob-flip_label\": \"Irrel. Context, Low-freq.\",\n",
    "    \"eval-relevant_context-none\": \"Rel. Context, IBD\",\n",
    "    \"eval-relevant_context-none-flip_label\": \"Rel. Context, OOBD\",\n",
    "    \"eval-irrelevant_context-none\": \"Irrel. Context, High-freq., IBD\",\n",
    "    \"eval-irrelevant_context-none-flip_label\": \"Irrel. Context, OOBD\",\n",
    "    \"eval-default-none\": \"IBD\",\n",
    "    \"eval-default-none-flip_label\": \"OOBD\",\n",
    "}\n",
    "\n",
    "eval_names = [\n",
    "    \"eval-default-none\",\n",
    "    \"eval-default-none-flip_label\",\n",
    "]\n",
    "\n",
    "num_rows = 2\n",
    "num_cols = len(num_contextss)\n",
    "fig, axes = plt.subplots(\n",
    "    num_rows,\n",
    "    num_cols,\n",
    "    figsize=set_size(doc_width_pt, 0.95, (num_rows, num_cols), use_golden_ratio=True),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "for col_i, num_contexts in enumerate(num_contextss):\n",
    "    for eval_i, eval_name in enumerate(eval_names):\n",
    "        ax = axes[eval_i, col_i]\n",
    "        for p_relevant_context in [0.0, 0.9, 1.0]:\n",
    "            losses_mean = []\n",
    "            losses_std = []\n",
    "\n",
    "            for dataset_size in dataset_sizes:\n",
    "                data = 1 - (np.array(stats[\n",
    "                    (stats[\"p_relevant_context\"] == f\"{p_relevant_context}\")\n",
    "                    & (stats[\"num_contexts\"] == f\"{num_contexts}\")\n",
    "                    & (stats[\"stats_key\"] == \"accuracy\")\n",
    "                    & (stats[\"eval_name\"] == eval_name)\n",
    "                    & (stats[\"dataset_size\"] == f\"{dataset_size}\")\n",
    "                ][\"stats\"].to_list()))\n",
    "                best_idx = best_idxes[(\n",
    "                    p_relevant_context, num_contexts, dataset_size\n",
    "                )]\n",
    "                sample = data[np.arange(5), best_idx]\n",
    "                curr_mean = np.mean(sample)\n",
    "                curr_std = np.std(sample)\n",
    "                \n",
    "                losses_mean.append(curr_mean)\n",
    "                losses_std.append(curr_std)\n",
    "\n",
    "            losses_mean = np.array(losses_mean)\n",
    "            losses_std = np.array(losses_std) / np.sqrt(5)\n",
    "\n",
    "            ax.plot(np.log2(np.array(dataset_sizes)), losses_mean, label=map_label[p_relevant_context] if eval_i == 0 and col_i == 0 else \"\")\n",
    "            ax.fill_between(np.log2(np.array(dataset_sizes)), losses_mean - losses_std, losses_mean + losses_std, alpha=0.3)\n",
    "\n",
    "        ax.axhline(9/10, label=\"Chance\" if eval_i == 0 and col_i == 0 else \"\", c=\"black\", linestyle=\"--\")\n",
    "        ax.set_ylim(-0.1, 1.1)\n",
    "        loc = plticker.MultipleLocator(base=2.0) # this locator puts ticks at regular intervals\n",
    "        ax.xaxis.set_major_locator(loc)\n",
    "\n",
    "        if col_i == 0:\n",
    "            ax.set_ylabel(map_eval[eval_name], fontsize=\"8\")\n",
    "        \n",
    "        if col_i > 0:\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        if eval_i == 0:\n",
    "            ax.set_xticks([])\n",
    "    \n",
    "    axes[0, col_i].set_title(f\"$L = {num_contexts}$\", fontsize=\"8\")\n",
    "\n",
    "# fig.suptitle(\"Input Noise\")\n",
    "fig.supylabel(\"0-1 Error\", fontsize=\"8\")\n",
    "fig.supxlabel(\"Dataset Size (in $\\\\log_2$)\", fontsize=\"8\")\n",
    "fig.legend(\n",
    "    bbox_to_anchor=(0.0, 1.0, 1.0, 0.0),\n",
    "    loc=\"lower center\",\n",
    "    ncols=4,\n",
    "    borderaxespad=0.0,\n",
    "    frameon=True,\n",
    "    fontsize=\"8\", \n",
    ")\n",
    "# fig.tight_layout()\n",
    "plt.savefig(\"num_contexts.pdf\", dpi=600, format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as plticker\n",
    "map_label = {\n",
    "    0.0: \"IW Predictor\",\n",
    "    1.0: \"IC Predictor\",\n",
    "    0.9: \"Transformer\",\n",
    "}\n",
    "map_eval = {\n",
    "    \"eval-relevant_context-high_prob\": \"Rel. Cont., $C_H$\",\n",
    "    \"eval-relevant_context-low_prob\": \"Rel. Cont., $C_L$\",\n",
    "    \"eval-irrelevant_context-high_prob\": \"Irrel. Cont., $C_H$\",\n",
    "    \"eval-irrelevant_context-low_prob\": \"Irrel. Cont., $C_L$\",\n",
    "    \"eval-relevant_context-high_prob-flip_label\": \"Rel. Cont., $C_H$\",\n",
    "    \"eval-relevant_context-low_prob-flip_label\": \"Rel. Cont., $C_L$\",\n",
    "    \"eval-irrelevant_context-high_prob-flip_label\": \"Irrel. Cont., $C_H$\",\n",
    "    \"eval-irrelevant_context-low_prob-flip_label\": \"Irrel. Cont., $C_L$\",\n",
    "    \"eval-relevant_context-none\": \"Rel. Context, IBD\",\n",
    "    \"eval-relevant_context-none-flip_label\": \"Rel. Context, OOBD\",\n",
    "    \"eval-irrelevant_context-none\": \"Irrel. Context, High-freq., IBD\",\n",
    "    \"eval-irrelevant_context-none-flip_label\": \"Irrel. Context, OOBD\",\n",
    "    \"eval-default-none\": \"In-base Dist.\",\n",
    "    \"eval-default-none-flip_label\": \"Out-of-base Dist.\",\n",
    "}\n",
    "\n",
    "eval_namess = [\n",
    "    [\n",
    "        \"eval-relevant_context-high_prob\",\n",
    "        \"eval-relevant_context-low_prob\",\n",
    "        \"eval-irrelevant_context-high_prob\",\n",
    "        \"eval-irrelevant_context-low_prob\",\n",
    "    ],\n",
    "    [\n",
    "        \"eval-relevant_context-high_prob-flip_label\",\n",
    "        \"eval-relevant_context-low_prob-flip_label\",\n",
    "        \"eval-irrelevant_context-high_prob-flip_label\",\n",
    "        \"eval-irrelevant_context-low_prob-flip_label\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "num_rows = 2\n",
    "num_cols = 4\n",
    "fig, axes = plt.subplots(\n",
    "    num_rows,\n",
    "    num_cols,\n",
    "    figsize=set_size(doc_width_pt, 0.95, (num_rows, num_cols), use_golden_ratio=True),\n",
    "    # figsize=(10, 5),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "dataset_size = dataset_sizes[-3]\n",
    "print(dataset_size)\n",
    "for row_i, eval_names in enumerate(eval_namess):\n",
    "    for col_i, eval_name in enumerate(eval_names):\n",
    "\n",
    "        ax = axes[row_i, col_i]\n",
    "\n",
    "        for p_relevant_context in [0.0, 0.9, 1.0]:\n",
    "            losses_mean = []\n",
    "            losses_std = []\n",
    "            for num_contexts in num_contextss:\n",
    "                data = 1 - (np.array(stats[\n",
    "                    (stats[\"p_relevant_context\"] == f\"{p_relevant_context}\")\n",
    "                    & (stats[\"num_contexts\"] == f\"{num_contexts}\")\n",
    "                    & (stats[\"stats_key\"] == \"accuracy\")\n",
    "                    & (stats[\"eval_name\"] == eval_name)\n",
    "                    & (stats[\"dataset_size\"] == f\"{dataset_size}\")\n",
    "                ][\"stats\"].to_list()))\n",
    "                best_idx = best_idxes[(\n",
    "                    p_relevant_context, num_contexts, dataset_size\n",
    "                )]\n",
    "                sample = data[np.arange(5), best_idx]\n",
    "                curr_mean = np.mean(sample)\n",
    "                curr_std = np.std(sample)\n",
    "                \n",
    "                losses_mean.append(curr_mean)\n",
    "                losses_std.append(curr_std)\n",
    "\n",
    "            losses_mean = np.array(losses_mean)\n",
    "            losses_std = np.array(losses_std) / np.sqrt(5)\n",
    "\n",
    "            ax.plot(np.log2(num_contextss), losses_mean, label=map_label[p_relevant_context] if row_i == 0 and col_i == 0 else \"\", marker=\"x\")\n",
    "            ax.fill_between(np.log2(num_contextss), losses_mean - losses_std, losses_mean + losses_std, alpha=0.3)\n",
    "\n",
    "        ax.axhline(9/10, label=\"Chance\" if row_i == 0 and col_i == 0 else \"\", c=\"black\", linestyle=\"--\")\n",
    "        ax.set_ylim(-0.1, 1.1)\n",
    "        loc = plticker.MultipleLocator(base=1.0) # this locator puts ticks at regular intervals\n",
    "        ax.xaxis.set_major_locator(loc)\n",
    "\n",
    "        if col_i == 0:\n",
    "            ax.set_ylabel(\"IBD\" if row_i == 0 else \"OOBD\", fontsize=\"8\")\n",
    "\n",
    "        if col_i > 0:\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        if row_i == 0:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_title(map_eval[eval_name], fontsize=\"8\")\n",
    "\n",
    "# fig.suptitle(\"Input Noise\")\n",
    "fig.supylabel(\"0-1 Error\", fontsize=\"8\")\n",
    "fig.supxlabel(\"$L$ (in $\\\\log_2$)\", fontsize=\"8\")\n",
    "fig.legend(\n",
    "    bbox_to_anchor=(0.0, 1.0, 1.0, 0.0),\n",
    "    loc=\"lower center\",\n",
    "    ncols=4,\n",
    "    borderaxespad=0.0,\n",
    "    frameon=True,\n",
    "    fontsize=\"8\", \n",
    ")\n",
    "plt.savefig(\"num_contexts-l.pdf\", dpi=600, format=\"pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c77b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbb0456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
