{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_size, pgf_with_latex\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "sys.path.insert(0, \"../src\")\n",
    "\n",
    "from experiments.utils import *\n",
    "\n",
    "from src.constants import *\n",
    "from src.dataset import get_data_loader\n",
    "from src.utils import parse_dict, load_config, iterate_models, set_seed\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import os\n",
    "\n",
    "import _pickle as pickle\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import timeit\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "# Penzai\n",
    "from penzai import pz\n",
    "\n",
    "import IPython\n",
    "\n",
    "pz.ts.register_as_default()\n",
    "\n",
    "# Optional automatic array visualization extras:\n",
    "pz.ts.register_autovisualize_magic()\n",
    "pz.enable_interactive_context()\n",
    "pz.ts.active_autovisualizer.set_interactive(pz.ts.ArrayAutovisualizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-v0_8-colorblind\")\n",
    "plt.rcParams.update(pgf_with_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dir = \"/Users/chanb/research/ualberta/simple_icl/experiments/results\"\n",
    "# experiment_name = \"high_prob_0.99\"\n",
    "# variant = \"transformer-09-02-24_13_39_27-bf1eeb21-928a-4829-b008-f82e5369e4d0\"\n",
    "\n",
    "# learner_path = os.path.join(log_dir, experiment_name, variant)\n",
    "\n",
    "# learner_path = \"/Users/chanb/research/ualberta/icl/cc_results/paper_experiments/results/synthetic-transformer-p_relevant/dataset_size_16384-p_relevant_context_0.99-seed_0-09-18-24_22_42_11-43f5227d-b0c5-4f3a-984f-b45ad9a8e238\"\n",
    "learner_path = \"/Users/chanb/research/ualberta/icl/cc_results/paper_experiments/results/synthetic-transformer-p_relevant/dataset_size_1024-p_relevant_context_0.99-seed_0-09-18-24_22_41_46-26651528-70d9-40f2-998a-1959fe28a94e\"\n",
    "# learner_path = \"/Users/chanb/research/ualberta/icl/cc_results/paper_experiments/results/synthetic-transformer-p_relevant/dataset_size_1048576-p_relevant_context_0.99-seed_0-09-21-24_16_36_00-11712db5-c996-4adb-bd63-2c9d977c2f30\"\n",
    "# learner_path = \"/Users/chanb/research/ualberta/icl/cc_results/paper_experiments/omniglot_models-attention/dataset_size_10000-p_relevant_context_0.9-input_noise_std_0.0-seed_0-09-25-24_22_02_30-e889951d-e10c-4e8a-96d7-b646b4e50249\"\n",
    "# learner_path = \"/Users/chanb/research/ualberta/icl/cc_results/paper_experiments/omniglot_models-attention/dataset_size_1000000-p_relevant_context_0.9-input_noise_std_0.0-seed_0-09-25-24_22_04_21-97704873-1c50-4b22-83e3-64b89b5fd30a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iter = iterate_models(\n",
    "    learner_path\n",
    ")\n",
    "\n",
    "params_init, model, checkpoint_step_init = next(model_iter)\n",
    "\n",
    "for params_next, _, checkpoint_step_next in model_iter:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 20\n",
    "\n",
    "samples_path = \"/Users/chanb/research/ualberta/icl/cc_results/paper_experiments/omniglot_models-attention/samples.pkl\"\n",
    "if os.path.isfile(samples_path):\n",
    "    samples = pickle.load(open(samples_path, \"rb\"))\n",
    "else:\n",
    "    samples = []\n",
    "    config_dict, config = load_config(learner_path)\n",
    "    config_dict[\"batch_size\"] = 1\n",
    "    config_dict[\"dataset_kwargs\"][\"flip_label\"] = 1\n",
    "    config_dict[\"dataset_kwargs\"][\"p_high\"] = 0.5\n",
    "    config = parse_dict(config_dict)\n",
    "    print(config)\n",
    "\n",
    "    train_data_loader, train_dataset = get_data_loader(\n",
    "        config\n",
    "    )\n",
    "    for batch in train_data_loader:\n",
    "        # if np.argmax(batch[\"target\"][0, -1], axis=-1) == 1:\n",
    "        #     break\n",
    "        labels = np.argmax(batch[\"target\"], axis=-1)\n",
    "        # if np.sum(labels[:, :-1] == labels[:, [-1]]) == 0:\n",
    "        #     break\n",
    "        if np.sum(labels[:, :-1] == labels[:, [-1]]) > 0:\n",
    "            samples.append(batch)\n",
    "\n",
    "        # print(labels)\n",
    "        # if labels[0, -1] <= 4 and np.sum(labels[:, :-1] == labels[:, [-1]]) == 0:\n",
    "        #     break\n",
    "\n",
    "        if len(samples) == num_samples:\n",
    "            break\n",
    "    pickle.dump(samples, open(samples_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for batch in samples:\n",
    "    result = dict()\n",
    "    result[\"label\"] = np.argmax(batch[\"target\"], axis=-1)\n",
    "    for params, checkpoint_step in zip(\n",
    "        [params_init, params_next],\n",
    "        [checkpoint_step_init, checkpoint_step_next]\n",
    "    ):\n",
    "        out, aux = model.get_attention(\n",
    "            params[CONST_MODEL],\n",
    "            batch,\n",
    "            eval=True,\n",
    "        )\n",
    "\n",
    "        result[checkpoint_step] = dict()\n",
    "        for block in aux[\"gpt\"][\"intermediates\"]:\n",
    "            if not block.startswith(\"GPTBlock_\"):\n",
    "                continue\n",
    "\n",
    "            # axis=1 -> query\n",
    "            # axis=2 -> key\n",
    "            self_attention_map = jax.nn.softmax(aux[\"gpt\"][\"intermediates\"][block][\"SelfAttentionModule_0\"][\"attention\"][0][0])\n",
    "            self_attention_map = self_attention_map.at[self_attention_map <= -1e10].set(jnp.nan)\n",
    "\n",
    "            attention_score = jnp.sum(aux[\"gpt\"][\"intermediates\"][block][\"attention\"][0][0], axis=-1)\n",
    "            input_vector = jnp.sum(aux[\"gpt\"][\"intermediates\"][block][\"input\"][0][0], axis=-1)\n",
    "            block_output = jnp.sum(aux[\"gpt\"][\"intermediates\"][block][\"block_out\"][0][0], axis=-1)\n",
    "\n",
    "            result[checkpoint_step][block] = dict(\n",
    "                self_attention_map=self_attention_map,\n",
    "                attention_score=attention_score,\n",
    "                input_vector=jnp.vstack(\n",
    "                    (\n",
    "                        np.argmax(batch[\"target\"][0], axis=-1),\n",
    "                        input_vector[::2],\n",
    "                        jnp.concatenate((input_vector[1::2], jnp.array([jnp.nan])), axis=-1),\n",
    "                    )\n",
    "                ),\n",
    "                block_output=jnp.vstack(\n",
    "                    (\n",
    "                        np.argmax(batch[\"target\"][0], axis=-1),\n",
    "                        block_output[::2],\n",
    "                        jnp.concatenate((block_output[1::2], jnp.array([jnp.nan])), axis=-1),\n",
    "                    )\n",
    "                ),\n",
    "            )\n",
    "        \n",
    "        pred, _ = model.forward(\n",
    "            params[CONST_MODEL],\n",
    "            batch,\n",
    "            eval=True,\n",
    "        )\n",
    "        result[checkpoint_step][\"prediction\"] = pred\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "    if len(results) == num_samples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz.ts.display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = min(10, num_samples)\n",
    "num_rows = len(results) // num_cols * 3\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=set_size(500, 1, (num_rows, num_cols), use_golden_ratio=False), layout=\"constrained\")\n",
    "\n",
    "for res_i, curr_res in enumerate(results):\n",
    "    curr_col = res_i % num_cols\n",
    "    ax = axes[3 * (res_i // num_cols), curr_col]\n",
    "    labels = curr_res[\"label\"]\n",
    "    attention_map = curr_res[50000][\"GPTBlock_0\"][\"self_attention_map\"]\n",
    "    # attention_map = (np.nanmax(attention_map) - attention_map) / (np.nanmax(attention_map) - np.nanmin(attention_map))\n",
    "    im = ax.imshow(attention_map[0])\n",
    "    loc = plticker.MultipleLocator(base=1.0) # this locator puts ticks at regular intervals\n",
    "    ax.xaxis.set_major_locator(loc)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    ax.set_title(\"$y$: {}\".format(labels[..., 0].item()))\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    if curr_col > 0:\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    ax = axes[3 * (res_i // num_cols) + 1, res_i % num_cols]\n",
    "    attention_map = curr_res[50000][\"GPTBlock_1\"][\"self_attention_map\"]\n",
    "    # attention_map = (np.nanmax(attention_map) - attention_map) / (np.nanmax(attention_map) - np.nanmin(attention_map))\n",
    "    im = ax.imshow(attention_map[0])\n",
    "    loc = plticker.MultipleLocator(base=1.0) # this locator puts ticks at regular intervals\n",
    "    ax.xaxis.set_major_locator(loc)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "\n",
    "    if curr_col > 0:\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    ax = axes[3 * (res_i // num_cols) + 2, res_i % num_cols]\n",
    "    pred = curr_res[50000][\"prediction\"]\n",
    "    # attention_map = (np.nanmax(attention_map) - attention_map) / (np.nanmax(attention_map) - np.nanmin(attention_map))\n",
    "    im = ax.imshow(jax.nn.softmax(pred))\n",
    "    loc = plticker.MultipleLocator(base=10.0) # this locator puts ticks at regular intervals\n",
    "    ax.xaxis.set_major_locator(loc)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(\"$\\\\hat{{y}}: {}$\".format(np.argmax(pred, axis=-1).item()))\n",
    "\n",
    "# axis=1 -> query\n",
    "# axis=2 -> key\n",
    "cax, kw = mpl.colorbar.make_axes([ax for ax in axes.flat])\n",
    "plt.colorbar(im, cax=cax, **kw)\n",
    "plt.savefig(\"attention-{}.pdf\".format(os.path.basename(learner_path)), dpi=600, format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = 10\n",
    "num_rows = len(results) // num_cols * 3\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=set_size(1500, 1, (num_rows, num_cols), use_golden_ratio=False))\n",
    "\n",
    "for res_i, curr_res in enumerate(results):\n",
    "    ax = axes[3 * (res_i // num_cols), res_i % num_cols]\n",
    "    labels = curr_res[\"label\"]\n",
    "    attention_map = curr_res[50000][\"GPTBlock_0\"][\"self_attention_map\"]\n",
    "    # attention_map = (np.nanmax(attention_map) - attention_map) / (np.nanmax(attention_map) - np.nanmin(attention_map))\n",
    "    im = ax.imshow(attention_map[0])\n",
    "    loc = plticker.MultipleLocator(base=1.0) # this locator puts ticks at regular intervals\n",
    "    ax.xaxis.set_major_locator(loc)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    ax.set_title(\"sample: {} - {}\".format(res_i, labels[..., 0].item()))\n",
    "\n",
    "    ax = axes[3 * (res_i // num_cols) + 1, res_i % num_cols]\n",
    "    attention_map = curr_res[50000][\"GPTBlock_1\"][\"self_attention_map\"]\n",
    "    # attention_map = (np.nanmax(attention_map) - attention_map) / (np.nanmax(attention_map) - np.nanmin(attention_map))\n",
    "    im = ax.imshow(attention_map[0])\n",
    "    loc = plticker.MultipleLocator(base=1.0) # this locator puts ticks at regular intervals\n",
    "    ax.xaxis.set_major_locator(loc)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "\n",
    "    ax = axes[3 * (res_i // num_cols) + 2, res_i % num_cols]\n",
    "    pred = curr_res[50000][\"prediction\"]\n",
    "    # attention_map = (np.nanmax(attention_map) - attention_map) / (np.nanmax(attention_map) - np.nanmin(attention_map))\n",
    "    im = ax.imshow(jax.nn.softmax(pred))\n",
    "    loc = plticker.MultipleLocator(base=1.0) # this locator puts ticks at regular intervals\n",
    "    ax.xaxis.set_major_locator(loc)\n",
    "    ax.set_yticks([])\n",
    "\n",
    "# axis=1 -> query\n",
    "# axis=2 -> key\n",
    "cax, kw = mpl.colorbar.make_axes([ax for ax in axes.flat])\n",
    "plt.colorbar(im, cax=cax, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
