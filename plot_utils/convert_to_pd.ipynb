{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "611aa6db-9102-41d8-a575-6da09450a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import timeit\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b7a68a-60d0-4758-b3f9-b5ef665b2722",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_keys = [\n",
    "    \"accuracy\",\n",
    "    \"p_iwl\",\n",
    "    \"context contains query class\",\n",
    "    \"ic_pred\",\n",
    "    \"iw_pred\",\n",
    "    \"num p_iwl >= 0.5\",\n",
    "    \"p_iwl given context contains query class\",\n",
    "    \"loss\"\n",
    "    # \"similarity\",\n",
    "]\n",
    "\n",
    "# Transformer\n",
    "stats_keys = [\n",
    "    \"accuracy\",\n",
    "    \"context contains query class\",\n",
    "    \"loss\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f33f59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo_path = \"/Users/chanb/research/ualberta/icl/simple_icl\"\n",
    "# results_dir = \"/Users/chanb/research/ualberta/icl/scratch/evaluation_results\"\n",
    "# results_dir = \"/Users/chanb/research/ualberta/icl/cc_results/evaluation_results\"\n",
    "# results_dir = \"/Users/chanb/research/ualberta/icl/cc_results/noisy_labels_0.01/evaluation_results\"\n",
    "# results_dir = \"/Users/chanb/research/ualberta/icl/cc_results/paper_experiments/evaluation_results\"\n",
    "# results_dir = \"/Users/chanb/research/ualberta/icl/simple_icl/experiments/test_convergence_eval\"\n",
    "\n",
    "repo_path = \"/Users/chanb/research/ualberta/icl/simple_icl\"\n",
    "results_dir = \"/Users/chanb/research/ualberta/icl/cc_results/paper_experiments/evaluation_results\"\n",
    "\n",
    "# repo_path = \"/home/chanb/src/simple_icl\"\n",
    "# results_dir = \"/home/chanb/scratch/simple_icl/results\"\n",
    "\n",
    "repo_path = \"/home/bryanpu1/projects/icl/simple_icl\"\n",
    "# results_dir = \"/home/bryanpu1/projects/icl/scratch/evaluation_results\"\n",
    "results_dir = \"/home/bryanpu1/projects/icl/cc_results/evaluation_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e5fe6a4-d543-4e4e-9857-94bb492adc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variant_name = \"synthetic-simple_icl\"\n",
    "# variant_name = \"synthetic-transformer\"\n",
    "# variant_name = \"synthetic-transformer-context_len\"\n",
    "# variant_name = \"synthetic-transformer-large_num_low_freq\"\n",
    "# variant_name = \"synthetic-transformer-large_num_low_freq-input_noise_0.2\"\n",
    "# variant_name = \"synthetic-transformer-no_noise\"\n",
    "# variant_name = \"synthetic-transformer-noisy_inputs_0.2\"\n",
    "# variant_name = \"synthetic-transformer-noisy_labels_0.01\"\n",
    "# variant_name = \"synthetic-transformer-noisy_labels_0.1\"\n",
    "# variant_name = \"synthetic-transformer-num_relevant_contexts\"\n",
    "\n",
    "# variant_name = \"omniglot-input_noise-larger_bs\"\n",
    "variant_name = \"omniglot-input_noise\"\n",
    "variant_name = \"omniglot-p_high\"\n",
    "# variant_name = \"omniglot-p_relevant\"\n",
    "# variant_name = \"omniglot-num_contexts\"\n",
    "# variant_name = \"omniglot-num_relevant_contexts\"\n",
    "\n",
    "# variant_name = \"synthetic-transformer-noisy_inputs\"\n",
    "# variant_name = \"synthetic-transformer-noisy_labels\"\n",
    "# variant_name = \"synthetic-transformer-num_contexts\"\n",
    "# variant_name = \"synthetic-transformer-num_low_freq\"\n",
    "# variant_name = \"synthetic-transformer-num_relevant_contexts\"\n",
    "# variant_name = \"synthetic-transformer-input_noise-longer_epoch\"\n",
    "# variant_name = \"synthetic-transformer-p_high\"\n",
    "# variant_name = \"synthetic-transformer-p_relevant\"\n",
    "\n",
    "os.makedirs(\n",
    "    os.path.join(repo_path, \"plot_utils/plots/agg_stats\"),\n",
    "    exist_ok=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20cf71d4-8e3a-4733-bd0c-4848c06b6cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57a1ff7822d4d1791f4fc007395734e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats_file = os.path.join(repo_path, \"plot_utils/plots/agg_stats\", \"{}.feather\".format(variant_name))\n",
    "\n",
    "NUM_PARALLEL = 2\n",
    "\n",
    "minibatch_count = 0\n",
    "minibatch_content = \"\"\n",
    "if os.path.isfile(stats_file):\n",
    "    stats = pd.read_feather(stats_file)\n",
    "else:\n",
    "    stats = []\n",
    "\n",
    "    if variant_name == \"synthetic-simple_icl\":\n",
    "        all_dirs = [\n",
    "            \"synthetic-alpha\",\n",
    "            \"synthetic-ic_predictor\",\n",
    "            \"synthetic-iw_predictor\",\n",
    "        ]\n",
    "    else:\n",
    "        all_dirs = [variant_name]\n",
    "\n",
    "    for curr_dir in all_dirs:\n",
    "        curr_results_dir = os.path.join(results_dir, curr_dir)\n",
    "        if repo_path.startswith(\"/Users\"):\n",
    "            it = tqdm(os.listdir(curr_results_dir))\n",
    "        else:\n",
    "            # it = os.listdir(curr_results_dir)\n",
    "            it = tqdm(os.listdir(curr_results_dir))\n",
    "\n",
    "        for run_name in it:\n",
    "            tic = timeit.default_timer()\n",
    "\n",
    "            if os.path.isdir(os.path.join(curr_results_dir, run_name)) and run_name.startswith(\"p_relevant_context\"):\n",
    "                # IC/IW\n",
    "                for baseline_name in os.listdir(os.path.join(curr_results_dir, run_name)):\n",
    "                    prefix = \"-\".join(baseline_name.split(\"-\")[:-9])\n",
    "                    seed = baseline_name.split(\"-\")[-9]\n",
    "\n",
    "                    data = pickle.load(open(os.path.join(curr_results_dir, run_name, baseline_name), \"rb\"))\n",
    "                    for eval_name in data[\"stats\"]:\n",
    "                        for stats_key in stats_keys:\n",
    "                            if not stats_key in data[\"stats\"][eval_name]:\n",
    "                                continue\n",
    "\n",
    "                            factor = 1\n",
    "                            if stats_key == \"accuracy\":\n",
    "                                factor = 1 / 100\n",
    "\n",
    "                            stats.append(\n",
    "                                dict(\n",
    "                                    model_type=\"iw\" if \"p_relevant_context_0.0\" in baseline_name else \"ic\",\n",
    "                                    dirname=curr_dir,\n",
    "                                    variant=prefix,\n",
    "                                    seed=seed,\n",
    "                                    eval_name=eval_name,\n",
    "                                    stats_key=stats_key,\n",
    "                                    stats=[float(val) * factor for val in data[\"stats\"][eval_name][stats_key]],\n",
    "                                    **{\n",
    "                                        \"_\".join(key_val.split(\"_\")[:-1]): key_val.split(\"_\")[-1] for key_val in prefix.split(\"-\")\n",
    "                                    },\n",
    "                                )\n",
    "                            )\n",
    "                            stats[-1][\"p_relevant_context\"] = run_name.split(\"_\")[-1]\n",
    "\n",
    "            else:\n",
    "                # Transformer\n",
    "                if \"p_relevant_context_0.0\" in run_name or \"p_relevant_context_1.0\" in run_name:\n",
    "                    continue\n",
    "\n",
    "                prefix = \"-\".join(run_name.split(\"-\")[:-9])\n",
    "                seed = run_name.split(\"-\")[-9]\n",
    "\n",
    "                data = pickle.load(open(os.path.join(curr_results_dir, run_name), \"rb\"))\n",
    "\n",
    "                minibatch_count += 1\n",
    "                \n",
    "                minibatch_content += \"JAX_PLATFORMS=cpu python {}/plot_utils/simulate_minibatches.py --evaluation_file={} --repo_path={} --results_dir={} &\\n\".format(\n",
    "                    repo_path,\n",
    "                    os.path.join(curr_results_dir, run_name),\n",
    "                    repo_path,\n",
    "                    results_dir,\n",
    "                )\n",
    "                if minibatch_count % NUM_PARALLEL == 0:\n",
    "                    minibatch_content += \"wait \\n\"\n",
    "\n",
    "                for eval_name in data[\"stats\"]:\n",
    "                    for stats_key in stats_keys:\n",
    "                        if not stats_key in data[\"stats\"][eval_name]:\n",
    "                            continue\n",
    "\n",
    "                        factor = 1\n",
    "                        if stats_key == \"accuracy\":\n",
    "                            factor = 1 / 100\n",
    "\n",
    "                        stats.append(\n",
    "                            dict(\n",
    "                                model_type=\"transformer\",\n",
    "                                dirname=curr_dir,\n",
    "                                variant=prefix,\n",
    "                                seed=seed,\n",
    "                                eval_name=eval_name,\n",
    "                                stats_key=stats_key,\n",
    "                                stats=[float(val) * factor for val in data[\"stats\"][eval_name][stats_key]],\n",
    "                                **{\n",
    "                                    \"_\".join(key_val.split(\"_\")[:-1]): key_val.split(\"_\")[-1] for key_val in prefix.split(\"-\")\n",
    "                                },\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "            toc = timeit.default_timer()\n",
    "    stats = pd.DataFrame(stats)\n",
    "    stats.to_feather(os.path.join(repo_path, \"plot_utils/plots/agg_stats\", \"{}.feather\".format(variant_name)))\n",
    "    minibatch_content += \"wait \\n\"\n",
    "\n",
    "with open(\"generate_fake_minibatches-{}.sh\".format(variant_name), \"w\") as f:\n",
    "    f.writelines(minibatch_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0de4892c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3078"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e271678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3078 entries, 0 to 3077\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   model_type          3078 non-null   object\n",
      " 1   dirname             3078 non-null   object\n",
      " 2   variant             3078 non-null   object\n",
      " 3   seed                3078 non-null   object\n",
      " 4   eval_name           3078 non-null   object\n",
      " 5   stats_key           3078 non-null   object\n",
      " 6   stats               3078 non-null   object\n",
      " 7   dataset_size        3078 non-null   object\n",
      " 8   p_relevant_context  3078 non-null   object\n",
      " 9   p_high              3078 non-null   object\n",
      "dtypes: object(10)\n",
      "memory usage: 240.6+ KB\n"
     ]
    }
   ],
   "source": [
    "stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87a0369a-d1d9-4e2a-a968-b34bd1779db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>dirname</th>\n",
       "      <th>variant</th>\n",
       "      <th>seed</th>\n",
       "      <th>eval_name</th>\n",
       "      <th>stats_key</th>\n",
       "      <th>stats</th>\n",
       "      <th>dataset_size</th>\n",
       "      <th>p_relevant_context</th>\n",
       "      <th>p_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformer</td>\n",
       "      <td>omniglot-p_high</td>\n",
       "      <td>dataset_size_10000-p_relevant_context_0.9-p_hi...</td>\n",
       "      <td>seed_1</td>\n",
       "      <td>eval-default-none-flip_label</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[0.0, 0.0, 0.08, 0.149, 0.174, 0.172, 0.169, 0...</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformer</td>\n",
       "      <td>omniglot-p_high</td>\n",
       "      <td>dataset_size_10000-p_relevant_context_0.9-p_hi...</td>\n",
       "      <td>seed_1</td>\n",
       "      <td>eval-default-none-flip_label</td>\n",
       "      <td>context contains query class</td>\n",
       "      <td>[0.898, 0.898, 0.898, 0.898, 0.898, 0.898, 0.8...</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transformer</td>\n",
       "      <td>omniglot-p_high</td>\n",
       "      <td>dataset_size_10000-p_relevant_context_0.9-p_hi...</td>\n",
       "      <td>seed_1</td>\n",
       "      <td>eval-default-none-flip_label</td>\n",
       "      <td>loss</td>\n",
       "      <td>[7.751866817474365, 7.627061367034912, 8.47843...</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transformer</td>\n",
       "      <td>omniglot-p_high</td>\n",
       "      <td>dataset_size_10000-p_relevant_context_0.9-p_hi...</td>\n",
       "      <td>seed_1</td>\n",
       "      <td>eval-default-high_prob-flip_label</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformer</td>\n",
       "      <td>omniglot-p_high</td>\n",
       "      <td>dataset_size_10000-p_relevant_context_0.9-p_hi...</td>\n",
       "      <td>seed_1</td>\n",
       "      <td>eval-default-high_prob-flip_label</td>\n",
       "      <td>context contains query class</td>\n",
       "      <td>[0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.9...</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>transformer</td>\n",
       "      <td>omniglot-p_high</td>\n",
       "      <td>dataset_size_100000-p_relevant_context_0.9-p_h...</td>\n",
       "      <td>seed_1</td>\n",
       "      <td>eval-irrelevant_context-low_prob</td>\n",
       "      <td>context contains query class</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3074</th>\n",
       "      <td>transformer</td>\n",
       "      <td>omniglot-p_high</td>\n",
       "      <td>dataset_size_100000-p_relevant_context_0.9-p_h...</td>\n",
       "      <td>seed_1</td>\n",
       "      <td>eval-irrelevant_context-low_prob</td>\n",
       "      <td>loss</td>\n",
       "      <td>[7.9077606201171875, 8.245863914489746, 7.7521...</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>transformer</td>\n",
       "      <td>omniglot-p_high</td>\n",
       "      <td>dataset_size_100000-p_relevant_context_0.9-p_h...</td>\n",
       "      <td>seed_1</td>\n",
       "      <td>pretraining</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[0.0001, 0.9694, 0.9698000000000001, 0.9714, 0...</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>transformer</td>\n",
       "      <td>omniglot-p_high</td>\n",
       "      <td>dataset_size_100000-p_relevant_context_0.9-p_h...</td>\n",
       "      <td>seed_1</td>\n",
       "      <td>pretraining</td>\n",
       "      <td>context contains query class</td>\n",
       "      <td>[0.9004, 0.9004, 0.9004, 0.9004, 0.9004, 0.900...</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>transformer</td>\n",
       "      <td>omniglot-p_high</td>\n",
       "      <td>dataset_size_100000-p_relevant_context_0.9-p_h...</td>\n",
       "      <td>seed_1</td>\n",
       "      <td>pretraining</td>\n",
       "      <td>loss</td>\n",
       "      <td>[7.7470550537109375, 0.26528120040893555, 0.22...</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3078 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_type          dirname  \\\n",
       "0     transformer  omniglot-p_high   \n",
       "1     transformer  omniglot-p_high   \n",
       "2     transformer  omniglot-p_high   \n",
       "3     transformer  omniglot-p_high   \n",
       "4     transformer  omniglot-p_high   \n",
       "...           ...              ...   \n",
       "3073  transformer  omniglot-p_high   \n",
       "3074  transformer  omniglot-p_high   \n",
       "3075  transformer  omniglot-p_high   \n",
       "3076  transformer  omniglot-p_high   \n",
       "3077  transformer  omniglot-p_high   \n",
       "\n",
       "                                                variant    seed  \\\n",
       "0     dataset_size_10000-p_relevant_context_0.9-p_hi...  seed_1   \n",
       "1     dataset_size_10000-p_relevant_context_0.9-p_hi...  seed_1   \n",
       "2     dataset_size_10000-p_relevant_context_0.9-p_hi...  seed_1   \n",
       "3     dataset_size_10000-p_relevant_context_0.9-p_hi...  seed_1   \n",
       "4     dataset_size_10000-p_relevant_context_0.9-p_hi...  seed_1   \n",
       "...                                                 ...     ...   \n",
       "3073  dataset_size_100000-p_relevant_context_0.9-p_h...  seed_1   \n",
       "3074  dataset_size_100000-p_relevant_context_0.9-p_h...  seed_1   \n",
       "3075  dataset_size_100000-p_relevant_context_0.9-p_h...  seed_1   \n",
       "3076  dataset_size_100000-p_relevant_context_0.9-p_h...  seed_1   \n",
       "3077  dataset_size_100000-p_relevant_context_0.9-p_h...  seed_1   \n",
       "\n",
       "                              eval_name                     stats_key  \\\n",
       "0          eval-default-none-flip_label                      accuracy   \n",
       "1          eval-default-none-flip_label  context contains query class   \n",
       "2          eval-default-none-flip_label                          loss   \n",
       "3     eval-default-high_prob-flip_label                      accuracy   \n",
       "4     eval-default-high_prob-flip_label  context contains query class   \n",
       "...                                 ...                           ...   \n",
       "3073   eval-irrelevant_context-low_prob  context contains query class   \n",
       "3074   eval-irrelevant_context-low_prob                          loss   \n",
       "3075                        pretraining                      accuracy   \n",
       "3076                        pretraining  context contains query class   \n",
       "3077                        pretraining                          loss   \n",
       "\n",
       "                                                  stats dataset_size  \\\n",
       "0     [0.0, 0.0, 0.08, 0.149, 0.174, 0.172, 0.169, 0...        10000   \n",
       "1     [0.898, 0.898, 0.898, 0.898, 0.898, 0.898, 0.8...        10000   \n",
       "2     [7.751866817474365, 7.627061367034912, 8.47843...        10000   \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        10000   \n",
       "4     [0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.9...        10000   \n",
       "...                                                 ...          ...   \n",
       "3073  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...       100000   \n",
       "3074  [7.9077606201171875, 8.245863914489746, 7.7521...       100000   \n",
       "3075  [0.0001, 0.9694, 0.9698000000000001, 0.9714, 0...       100000   \n",
       "3076  [0.9004, 0.9004, 0.9004, 0.9004, 0.9004, 0.900...       100000   \n",
       "3077  [7.7470550537109375, 0.26528120040893555, 0.22...       100000   \n",
       "\n",
       "     p_relevant_context p_high  \n",
       "0                   0.9   0.99  \n",
       "1                   0.9   0.99  \n",
       "2                   0.9   0.99  \n",
       "3                   0.9   0.99  \n",
       "4                   0.9   0.99  \n",
       "...                 ...    ...  \n",
       "3073                0.9   0.99  \n",
       "3074                0.9   0.99  \n",
       "3075                0.9   0.99  \n",
       "3076                0.9   0.99  \n",
       "3077                0.9   0.99  \n",
       "\n",
       "[3078 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30289046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
